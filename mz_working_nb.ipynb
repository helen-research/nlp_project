{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLAN\n",
    "\n",
    "- [ ] Acquisition\n",
    "    - [ ] Select what list of repos to scrape.\n",
    "    - [ ] Get requests form the site.\n",
    "    - [ ] Save responses to csv.\n",
    "- [ ] Preparation\n",
    "    - [ ] Prepare the data for analysis.\n",
    "- [ ] Exploration\n",
    "    - [ ] Answer the following prompts:\n",
    "        - [ ] What are the most common words in READMEs?\n",
    "        - [ ] What does the distribution of IDFs look like for the most common words?\n",
    "        - [ ] Does the length of the README vary by language?\n",
    "        - [ ] Do different languages use a different number of unique words?\n",
    "- [ ] Modeling\n",
    "    - [ ] Transform the data for machine learning; use language to predict.\n",
    "    - [ ] Fit several models using different text repressentations.\n",
    "    - [ ] Build a function that will take in the text of a README file, and makes a prediction of language.\n",
    "- [ ] Delivery\n",
    "    - [ ] Github repo\n",
    "        - [x] This notebook.\n",
    "        - [ ] Documentation within the notebook.\n",
    "        - [ ] README file in the repo.\n",
    "        - [ ] Python scripts if applicable.\n",
    "    - [ ] Google Slides\n",
    "        - [ ] 1-2 slides only summarizing analysis.\n",
    "        - [ ] Visualizations are labeled.\n",
    "        - [ ] Geared for the general audience.\n",
    "        - [ ] Share link @ readme file and/or classroom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "from requests import get\n",
    "import json\n",
    "# import spacy\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "from functools import reduce\n",
    "\n",
    "BASEURL = 'https://github.com/search?p=1&q=stars%3A%3E0&s=stars&type=Repositories'\n",
    "HEADERS = {'User-Agent': 'Definitely not Sentient Attack Helicoptor'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACQUIRE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing that needs to happen is to get the links from the most starred github repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_list(page):\n",
    "    urls = []\n",
    "    response = get(BASEURL, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content)\n",
    "    max_page = page + 1\n",
    "    for i in range(1,max_page):\n",
    "        url = 'https://github.com/search?p=' + str(i) + '&q=stars%3A%3E0&s=stars&type=Repositories'\n",
    "        print(f'traversing url: {url}')\n",
    "        response = get(url, headers=HEADERS)\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        list_of_repos = soup.find('ul', class_='repo-list')\n",
    "        repository = list_of_repos.find_all('li', class_='repo-list-item')\n",
    "        for h in repository:\n",
    "            if h.find(attrs={'itemprop':'programmingLanguage'}):\n",
    "                a = h.find('a')\n",
    "                urls.append(a.attrs['href'])\n",
    "        time.sleep(3)\n",
    "    print(f'Scraped a total of {len(urls)} github urls.')\n",
    "    urls = ['https://github.com' + url for url in urls]\n",
    "    with open('github_urls.csv', 'w') as f:\n",
    "        ghub_urls = csv.writer(f, delimiter=',')\n",
    "        ghub_urls.writerow(urls)\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function that grabs the readme text and the main language of the repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_readmes_and_languages(urls):\n",
    "    readmes = []\n",
    "    languages = []\n",
    "    for url in urls:\n",
    "        response = get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # print('Retrieving README')\n",
    "        if soup.find('div', class_='Box-body') == None:\n",
    "            # print('Skipping because of no README')\n",
    "            continue\n",
    "        else:\n",
    "            single_readme = soup.find('div', class_='Box-body').text\n",
    "            # print('Got README')\n",
    "        # print('Retrieving language')\n",
    "        if soup.find('span', class_='lang') == None:\n",
    "            # print('Skipping because of no language')\n",
    "            continue\n",
    "        else:\n",
    "            repo_language = soup.find('span', class_='lang').text\n",
    "            # print('Got language')\n",
    "        languages.append(repo_language)\n",
    "        readmes.append(single_readme)\n",
    "    df = pd.DataFrame({'readme':readmes, 'language':languages})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    \"\"\"Will lowercase, normalize, and remove anything that isn't a letter, number,\n",
    "    whitespace or single quote and return it.\"\"\"\n",
    "    clean_string = string.lower()\n",
    "    clean_string = unicodedata.normalize('NFKD', clean_string).\\\n",
    "                    encode('ascii', 'ignore').\\\n",
    "                    decode('utf-8', 'ignore')\n",
    "    clean_string = re.sub(r'[^a-z0-9\\s]', '', clean_string)\n",
    "    clean_string = clean_string.strip()\n",
    "    clean_string = re.sub(r'\\s+', ' ', clean_string)\n",
    "    return clean_string\n",
    "\n",
    "\n",
    "\n",
    "def tokenize(string, string_or_list='string'):\n",
    "    \"\"\"nltk.tokenize.ToktokTokenizer\"\"\"\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    if string_or_list == 'string':\n",
    "        return tokenizer.tokenize(string, return_str=True)\n",
    "    if string_or_list == 'list':\n",
    "        return tokenizer.tokenize(string)\n",
    "    \n",
    "def stem(string, string_or_list='string'):\n",
    "    \"\"\"Returns the stems.\"\"\"\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    stemmed_string = ' '.join(stems)\n",
    "    if string_or_list == 'list':\n",
    "        return stems\n",
    "    if string_or_list == 'string':\n",
    "        return stemmed_string\n",
    "    \n",
    "def lemmatize(string, string_or_list='string'):\n",
    "    \"\"\"Returns the lemmatized text.\"\"\"\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    lemmatized_string = ' '.join(lemmas)\n",
    "    if string_or_list == 'string':\n",
    "        return lemmatized_string\n",
    "    if string_or_list == 'list':\n",
    "        return lemmas\n",
    "    \n",
    "def remove_stopwords(string, string_or_list='string', extra_words=None, exclude_words=None):\n",
    "    \"\"\"Removes the stopwords from the text then returns it. Able to add or remove stopwords.\"\"\"\n",
    "    stopword_list = stopwords.words('english')\n",
    "    if extra_words != None:\n",
    "        for word in extra_words:\n",
    "            stopword_list.append(word)\n",
    "    if exclude_words != None:\n",
    "        for word in exclude_words:\n",
    "            stopword_list.remove(word)\n",
    "    filtered_words = [word for word in string.split() if word not in stopword_list]\n",
    "    filtered_string = ' '.join(filtered_words)\n",
    "    if string_or_list == 'string':\n",
    "        return filtered_string\n",
    "    if string_or_list == 'list':\n",
    "        return filtered_words\n",
    "    \n",
    "def pipe(v, *fns):\n",
    "    return reduce(lambda x, f: f(x), fns, v)\n",
    "\n",
    "# Master function for cleaning\n",
    "\n",
    "def readme_lem(text):\n",
    "    return pipe(text, basic_clean, tokenize, remove_stopwords, lemmatize)\n",
    "\n",
    "def readme_stem(text):\n",
    "    return pipe(text, basic_clean, tokenize, remove_stopwords, stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# urls = get_url_list(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('github_urls.csv') as f:\n",
    "    urls = f.readlines()\n",
    "urls = urls[0].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readme</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nWelcome to freeCodeCamp.org's open...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n996.ICU\\nPlease note that there exists NO ot...</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSupporting Vue.js\\nVue...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nBootstrap\\n\\n  Sleek, intuitive, a...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nReact 路    \\nReact is a JavaScript library f...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\nDocumentation\\n\\n\\n\\n\\n\\n\\n\\n\\...</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              readme    language\n",
       "0  \\n\\n\\n\\n\\n\\nWelcome to freeCodeCamp.org's open...  JavaScript\n",
       "1  \\n996.ICU\\nPlease note that there exists NO ot...        Rust\n",
       "2  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSupporting Vue.js\\nVue...  JavaScript\n",
       "3  \\n\\n\\n\\n\\n\\nBootstrap\\n\\n  Sleek, intuitive, a...  JavaScript\n",
       "4  \\nReact 路    \\nReact is a JavaScript library f...  JavaScript\n",
       "5  \\n\\n\\n\\n\\n\\n\\n\\nDocumentation\\n\\n\\n\\n\\n\\n\\n\\n\\...         C++"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = grab_readmes_and_languages(urls)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized'] = df.readme.apply(readme_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmed'] = df.readme.apply(readme_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readme</th>\n",
       "      <th>language</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nWelcome to freeCodeCamp.org's open...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>welcome freecodecamporgs open source codebase ...</td>\n",
       "      <td>welcom freecodecamporg open sourc codebas curr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n996.ICU\\nPlease note that there exists NO ot...</td>\n",
       "      <td>Rust</td>\n",
       "      <td>996icu please note exists official account app...</td>\n",
       "      <td>996icu pleas note exist offici account app mer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSupporting Vue.js\\nVue...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>supporting vuejs vuejs mitlicensed open source...</td>\n",
       "      <td>support vuej vuej mitlicens open sourc project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nBootstrap\\n\\n  Sleek, intuitive, a...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>bootstrap sleek intuitive powerful frontend fr...</td>\n",
       "      <td>bootstrap sleek intuit power frontend framewor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nReact 路    \\nReact is a JavaScript library f...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>react react javascript library building user i...</td>\n",
       "      <td>react react javascript librari build user inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              readme    language  \\\n",
       "0  \\n\\n\\n\\n\\n\\nWelcome to freeCodeCamp.org's open...  JavaScript   \n",
       "1  \\n996.ICU\\nPlease note that there exists NO ot...        Rust   \n",
       "2  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSupporting Vue.js\\nVue...  JavaScript   \n",
       "3  \\n\\n\\n\\n\\n\\nBootstrap\\n\\n  Sleek, intuitive, a...  JavaScript   \n",
       "4  \\nReact 路    \\nReact is a JavaScript library f...  JavaScript   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  welcome freecodecamporgs open source codebase ...   \n",
       "1  996icu please note exists official account app...   \n",
       "2  supporting vuejs vuejs mitlicensed open source...   \n",
       "3  bootstrap sleek intuitive powerful frontend fr...   \n",
       "4  react react javascript library building user i...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  welcom freecodecamporg open sourc codebas curr...  \n",
       "1  996icu pleas note exist offici account app mer...  \n",
       "2  support vuej vuej mitlicens open sourc project...  \n",
       "3  bootstrap sleek intuit power frontend framewor...  \n",
       "4  react react javascript librari build user inte...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996             13\n",
       "license         11\n",
       "list             8\n",
       "work             7\n",
       "company          7\n",
       "996icu           7\n",
       "please           5\n",
       "working          5\n",
       "open             5\n",
       "worker           5\n",
       "source           5\n",
       "employee         4\n",
       "schedule         4\n",
       "hour             4\n",
       "add              4\n",
       "github           4\n",
       "go               4\n",
       "right            4\n",
       "project          3\n",
       "founder          3\n",
       "labor            3\n",
       "icu              3\n",
       "chinese          3\n",
       "never            3\n",
       "see              3\n",
       "refers           2\n",
       "another          2\n",
       "overtime         2\n",
       "mean             2\n",
       "progress         2\n",
       "                ..\n",
       "least            1\n",
       "feeling          1\n",
       "back             1\n",
       "version          1\n",
       "control          1\n",
       "petition         1\n",
       "channel          1\n",
       "60               1\n",
       "voice            1\n",
       "youzan           1\n",
       "am9              1\n",
       "hear             1\n",
       "conduct          1\n",
       "unit             1\n",
       "alibaba          1\n",
       "anti             1\n",
       "financial        1\n",
       "uphold           1\n",
       "vanished         1\n",
       "give             1\n",
       "corp             1\n",
       "without          1\n",
       "way              1\n",
       "china            1\n",
       "wired            1\n",
       "occupational     1\n",
       "participate      1\n",
       "future           1\n",
       "practitioner     1\n",
       "speech           1\n",
       "Length: 281, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(' '.join(df[df.language == 'Rust'].lemmatized).split()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
